%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% datoteka diploma-FRI-vzorec.tex
%
%POZOR: ta verzija ne producira pdf datoteke v pdf/A formatu!!!
%namenjena je le za nalogo pri Diplomskem seminarju!
%
% vzorčna datoteka za pisanje diplomskega dela v formatu LaTeX
% na UL Fakulteti za računalništvo in informatiko
%
% na osnovi starejših verzij vkup spravil Franc Solina, maj 2021
% prvo verzijo je leta 2010 pripravil Gašper Fijavž
%
% za upravljanje z literaturo ta vezija uporablja BibLaTeX
%
% svetujemo uporabo Overleaf.com - na tej spletni implementaciji LaTeXa ta vzorec zagotovo pravilno deluje
%

\documentclass[a4paper,12pt,openright]{book}
%\documentclass[a4paper, 12pt, openright, draft]{book}  Nalogo preverite tudi z opcijo draft, ki pokaže, katere vrstice so predolge! Pozor, v draft opciji, se slike ne pokažejo!
 
\usepackage[utf8]{inputenc}   % omogoča uporabo slovenskih črk kodiranih v formatu UTF-8
\usepackage[slovene,english]{babel}    % naloži, med drugim, slovenske delilne vzorce
\usepackage[pdftex]{graphicx}  % omogoča vlaganje slik različnih formatov
\usepackage{fancyhdr}          % poskrbi, na primer, za glave strani
\usepackage{amssymb}           % dodatni matematični simboli
\usepackage{amsmath}           % eqref, npr.
\usepackage[pdftex, colorlinks=true,
						citecolor=black, filecolor=black, 
						linkcolor=black, urlcolor=black,
						pdfproducer={LaTeX}, pdfcreator={LaTeX}]{hyperref}
\usepackage{hyperxmp}
\usepackage[hyphens]{url}
\usepackage{csquotes}


\usepackage{color}
\usepackage{soul}

\graphicspath{{../results/}}

\usepackage{float}
\usepackage{booktabs}
\usepackage{xcolor}
\usepackage{makecell}
\definecolor{Apricot}{RGB}{251, 206, 177}

\usepackage[
backend=biber,
style=authoryear,
sorting=nty,
]{biblatex}


\addbibresource{literatura.bib} %Imports bibliography file


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	DIPLOMA INFO
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\ttitle}{Spodbujevano učenje na impulznih nevronskih mrežah}
\newcommand{\ttitleEn}{Reinforcement learning on spiking neural networks}
\newcommand{\tsubject}{\ttitle}
\newcommand{\tsubjectEn}{\ttitleEn}
\newcommand{\tauthor}{Matjaž Pogačnik}
\newcommand{\tkeywords}{impulzne nevronske mreže, spodbujevano učenje, R-STDP učenje, TD učenje}
\newcommand{\tkeywordsEn}{spiking neural networks, reinforcement learning, R-STDP learning, TD learning}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	HYPERREF SETUP
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\hypersetup{pdftitle={\ttitle}}
\hypersetup{pdfsubject=\ttitleEn}
\hypersetup{pdfauthor={\tauthor}}
\hypersetup{pdfkeywords=\tkeywordsEn}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% postavitev strani
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  

\addtolength{\marginparwidth}{-20pt} % robovi za tisk
\addtolength{\oddsidemargin}{40pt}
\addtolength{\evensidemargin}{-40pt}

\renewcommand{\baselinestretch}{1.3} % ustrezen razmik med vrsticami
\setlength{\headheight}{15pt}        % potreben prostor na vrhu
\renewcommand{\chaptermark}[1]%
{\markboth{\MakeUppercase{\thechapter.\ #1}}{}} \renewcommand{\sectionmark}[1]%
{\markright{\MakeUppercase{\thesection.\ #1}}} \renewcommand{\headrulewidth}{0.5pt} \renewcommand{\footrulewidth}{0pt}
\fancyhf{}
\fancyhead[LE,RO]{\sl \thepage} 
%\fancyhead[LO]{\sl \rightmark} \fancyhead[RE]{\sl \leftmark}
\fancyhead[RE]{\sc \tauthor}              % dodal Solina
\fancyhead[LO]{\sc Diplomska naloga}     % dodal Solina


\newcommand{\BibLaTeX}{{\sc Bib}\LaTeX}
\newcommand{\BibTeX}{{\sc Bib}\TeX}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% naslovi
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  

\newcommand{\autfont}{\Large}
\newcommand{\titfont}{\LARGE\bf}
\newcommand{\clearemptydoublepage}{\newpage{\pagestyle{empty}\cleardoublepage}}
\setcounter{tocdepth}{1}	      % globina kazala

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% konstrukti
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  
\newtheorem{izrek}{Izrek}[chapter]
\newtheorem{trditev}{Trditev}[izrek]
\newenvironment{dokaz}{\emph{Dokaz.}\ }{\hspace{\fill}{$\Box$}}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% PDF-A
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
% define medatata
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\def\Title{\ttitle}
\def\Author{\tauthor, matjaz.kralj@fri.uni-lj.si}
\def\Subject{\ttitleEn}
\def\Keywords{\tkeywordsEn}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
% \convertDate converts D:20080419103507+02'00' to 2008-04-19T10:35:07+02:00
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\def\convertDate{%
    \getYear
}

{\catcode`\D=12
 \gdef\getYear D:#1#2#3#4{\edef\xYear{#1#2#3#4}\getMonth}
}
\def\getMonth#1#2{\edef\xMonth{#1#2}\getDay}
\def\getDay#1#2{\edef\xDay{#1#2}\getHour}
\def\getHour#1#2{\edef\xHour{#1#2}\getMin}
\def\getMin#1#2{\edef\xMin{#1#2}\getSec}
\def\getSec#1#2{\edef\xSec{#1#2}\getTZh}
\def\getTZh +#1#2{\edef\xTZh{#1#2}\getTZm}
\def\getTZm '#1#2'{%
    \edef\xTZm{#1#2}%
    \edef\convDate{\xYear-\xMonth-\xDay T\xHour:\xMin:\xSec+\xTZh:\xTZm}%
}

%\expandafter\convertDate\pdfcreationdate 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% get pdftex version string
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\newcount\countA
\countA=\pdftexversion
\advance \countA by -100
\def\pdftexVersionStr{pdfTeX-1.\the\countA.\pdftexrevision}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% XMP data
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  
\usepackage{xmpincl}
%\includexmp{pdfa-1b}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% pdfInfo
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  
\pdfinfo{%
    /Title    (\ttitle)
    /Author   (\tauthor, damjan@cvetan.si)
    /Subject  (\ttitleEn)
    /Keywords (\tkeywordsEn)
    /ModDate  (\pdfcreationdate)
    /Trapped  /False
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% znaki za copyright stran
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  

\newcommand{\CcImageCc}[1]{%
	\includegraphics[scale=#1]{cc_cc_30.pdf}%
}
\newcommand{\CcImageBy}[1]{%
	\includegraphics[scale=#1]{cc_by_30.pdf}%
}
\newcommand{\CcImageSa}[1]{%
	\includegraphics[scale=#1]{cc_sa_30.pdf}%
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
\selectlanguage{slovene}
\frontmatter
\setcounter{page}{1} %
\renewcommand{\thepage}{}       % preprečimo težave s številkami strani v kazalu

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%naslovnica
 \thispagestyle{empty}%
   \begin{center}
    {\large\sc Univerza v Ljubljani\\%
%      Fakulteta za elektrotehniko\\% za študijski program Multimedija
%      Fakulteta za upravo\\% za študijski program Upravna informatika
      Fakulteta za računalništvo in informatiko\\%
%      Fakulteta za matematiko in fiziko\\% za študijski program Računalništvo in matematika
     }
    \vskip 10em%
    {\autfont \tauthor\par}%
    {\titfont \ttitle \par}%
    {\vskip 3em \textsc{DIPLOMSKO DELO\\[5mm]         % dodal Solina za ostale študijske programe
%    VISOKOŠOLSKI STROKOVNI ŠTUDIJSKI PROGRAM\\ PRVE STOPNJE\\ RAČUNALNIŠTVO IN INFORMATIKA}\par}%
     UNIVERZITETNI  ŠTUDIJSKI PROGRAM\\ PRVE STOPNJE\\ RAČUNALNIŠTVO IN INFORMATIKA}\par}%
%    INTERDISCIPLINARNI UNIVERZITETNI\\ ŠTUDIJSKI PROGRAM PRVE STOPNJE\\ MULTIMEDIJA}\par}%
%    INTERDISCIPLINARNI UNIVERZITETNI\\ ŠTUDIJSKI PROGRAM PRVE STOPNJE\\ UPRAVNA INFORMATIKA}\par}%
%    INTERDISCIPLINARNI UNIVERZITETNI\\ ŠTUDIJSKI PROGRAM PRVE STOPNJE\\ RAČUNALNIŠTVO IN MATEMATIKA}\par}%
    \vfill\null%
% izberite pravi habilitacijski naziv mentorja!
    {\large \textsc{Mentor}: prof. dr. Zoran Bosnić\par}%
%   {\large \textsc{Somentor}:  viš. pred./doc./izr. prof./prof. dr.  Martin Krpan \par}%
    {\vskip 2em \large Ljubljana, \the\year \par}%
\end{center}
% prazna stran
%\clearemptydoublepage      
% izjava o licencah itd. se izpiše na hrbtni strani naslovnice

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%copyright stran
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\thispagestyle{empty}

\vspace*{5cm}
{\small \noindent
To delo je ponujeno pod licenco \textit{Creative Commons Priznanje avtorstva-Deljenje pod enakimi pogoji 2.5 Slovenija} (ali novej\v so razli\v cico).
To pomeni, da se tako besedilo, slike, grafi in druge sestavine dela kot tudi rezultati diplomskega dela lahko prosto distribuirajo,
reproducirajo, uporabljajo, priobčujejo javnosti in predelujejo, pod pogojem, da se jasno in vidno navede avtorja in naslov tega
dela in da se v primeru spremembe, preoblikovanja ali uporabe tega dela v svojem delu, lahko distribuira predelava le pod
licenco, ki je enaka tej.
Podrobnosti licence so dostopne na spletni strani \href{http://creativecommons.si}{creativecommons.si} ali na Inštitutu za
intelektualno lastnino, Streliška 1, 1000 Ljubljana.

\vspace*{1cm}
\begin{center}% 0.66 / 0.89 = 0.741573033707865
\CcImageCc{0.741573033707865}\hspace*{1ex}\CcImageBy{1}\hspace*{1ex}\CcImageSa{1}%
\end{center}
}

\vspace*{1cm}
{\small \noindent
Izvorna koda diplomskega dela, njeni rezultati in v ta namen razvita programska oprema je ponujena pod licenco GNU General Public License,
različica 3 (ali novejša). To pomeni, da se lahko prosto distribuira in/ali predeluje pod njenimi pogoji.
Podrobnosti licence so dostopne na spletni strani \url{http://www.gnu.org/licenses/}.
}

\vfill
\begin{center} 
\ \\ \vfill
{\em
Besedilo je oblikovano z urejevalnikom besedil \LaTeX.}
\end{center}

% prazna stran
\clearemptydoublepage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% stran 3 med uvodnimi listi
\thispagestyle{empty}
\
\vfill

\bigskip
\noindent\textbf{Kandidat:} Matjaž Pogačnik\\
\noindent\textbf{Naslov:} Spodbujevano učenje na impulznih nevronskih mrežah\\
% vstavite ustrezen naziv študijskega programa!
\noindent\textbf{Vrsta naloge:} Diplomska naloga na univerzitetnem programu prve stopnje Računalništvo in informatika \\
% izberite pravi habilitacijski naziv mentorja!
\noindent\textbf{Mentor:} prof. dr. Zoran Bosnić\\
% \noindent\textbf{Somentor:} isto kot za mentorja

\bigskip
\noindent\textbf{Opis:}\\
\colorbox{Apricot}{%
  \parbox{0.9\linewidth}{%
Besedilo teme diplomskega dela študent prepiše iz študijskega informacijskega sistema, kamor ga je vnesel mentor. 
V nekaj stavkih bo opisal, kaj pričakuje od kandidatovega diplomskega dela. 
Kaj so cilji, kakšne metode naj uporabi, morda bo zapisal tudi ključno literaturo.
  }%
}

\bigskip
\noindent\textbf{Title:} Reinforcement learning on spiking neural networks

\bigskip
\noindent\textbf{Description:}\\
\colorbox{Apricot}{%
  \parbox{0.9\linewidth}{%
opis diplome v angleščini
    }
}

\vfill



\vspace{2cm}

% prazna stran
\clearemptydoublepage

% TODO: zahvala
% zahvala
\iffalse
\thispagestyle{empty}\mbox{}\vfill\null\it%
\noindent
Na tem mestu zapišite, komu se zahvaljujete za pomoč pri izdelavi diplomske naloge oziroma pri vašem študiju nasploh. Pazite, da ne boste koga pozabili. Utegnil vam bo zameriti. Temu se da izogniti tako, da celotno zahvalo izpustite.
\rm\normalfont

% prazna stran
\clearemptydoublepage
\fi

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% posvetilo, če sama zahvala ne zadošča :-)
%\thispagestyle{empty}\mbox{}{\vskip0.20\textheight}\mbox{}\hfill\begin{minipage}{0.55\textwidth}%
%Svoji dragi Alenčici.
%\normalfont\end{minipage}

% prazna stran
%\clearemptydoublepage


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% kazalo
\pagestyle{empty}
\def\thepage{}% preprečimo težave s številkami strani v kazalu
\tableofcontents{}


% prazna stran
\clearemptydoublepage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% seznam kratic

\chapter*{Seznam uporabljenih kratic}

\noindent\begin{tabular}{p{0.15\textwidth}|p{.36\textwidth}|p{.39\textwidth}}    % po potrebi razširi prvo kolono tabele na račun drugih dveh!
  {\bf kratica} & {\bf angleško}                              & {\bf slovensko} \\ \hline
  {\bf SNN}      & Spiking neural network               & Impulzna nevronska mreža \\
  {\bf R-STDP} & Reward modulated spike timing dependent plasticity & Sinaptična plastičnost odvisna od nagrajevanja in časovne razporeditve impulzov \\
  {\bf TD}   & Temporal difference              & Časovna razlika \\
%  \dots & \dots & \dots \\
\end{tabular}


% prazna stran
\clearemptydoublepage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% povzetek
\addcontentsline{toc}{chapter}{Povzetek}
\chapter*{Povzetek}

\noindent\textbf{Naslov:} \ttitle
\bigskip

\noindent\textbf{Avtor:} \tauthor
\bigskip

%\noindent\textbf{Povzetek:} 
\noindent 
%V vzorcu je predstavljen postopek priprave diplomskega dela z uporabo okolja \LaTeX. Vaš povzetek mora sicer vsebovati približno 100 besed, ta tukaj je odločno prekratek.
%Dober povzetek vključuje: (1) kratek opis obravnavanega problema, (2) kratek opis vašega pristopa za reševanje tega problema in (3) (najbolj uspešen) rezultat ali prispevek diplomske naloge.
V tem diplomskem delu obravnavamo spodbujevalno učenje na impulznih nevronskih mrežah, tipu nevronskih mrež, ki se obnašajo podobno kot človeški možgani. Ker tu ne moremo uporabiti klasičnih algoritmov spodbujevalnega učenja, postopoma razvijemo kompleksen sistem, navdihnjen z dopaminergičnimi mehanizmi v človeških možganih, ki omogoča učenje na podlagi časovne razlike. Pri tem postopoma rešujemo izzive pri učenju impulznih nevronskih mrež in na koncu uspešno rešimo problem tako s takojšnjo kot z oddaljeno nagrado.
\bigskip

\noindent\textbf{Ključne besede:} \tkeywords.
% prazna stran
\clearemptydoublepage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% abstract
\selectlanguage{english}
\addcontentsline{toc}{chapter}{Abstract}
\chapter*{Abstract}

\noindent\textbf{Title:} \ttitleEn
\bigskip

\noindent\textbf{Author:} \tauthor
\bigskip

%\noindent\textbf{Abstract:} 
\noindent %This sample document presents an approach to typesetting your BSc thesis using \LaTeX. 
%A proper abstract should contain around 100 words which makes this one way too short.
In this diploma thesis, we explore reinforcement learning in spiking neural networks, a type of neural network that resembles the human brain. As classic reinforcement learning algorithms cannot be directly applied to spiking neural networks, we gradually develop a complex system inspired by dopaminergic mechanisms in the human brain, which implements a form of temporal difference learning. During the development of the final system, we propose solutions to various problems associated with reinforcement learning in spiking neural networks and ultimately solve a problem involving both immediate and delayed rewards.
\bigskip

\noindent\textbf{Keywords:} \tkeywordsEn.
\selectlanguage{slovene}
% prazna stran
\clearemptydoublepage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\mainmatter
\setcounter{page}{1}
\pagestyle{fancy}

\chapter{Uvod}
\label{intro}
\section{Motivacija}
\label{sec:motive}
Impulzne nevronske mreže so v večini implementacij poskus modeliranja bioloških značilnosti nevronov in sinaps v možganih. Kot izjemno močan računski stroj, so možgani navdih za številne sodobne koncepte v umetni inteligenci. Najbolj očiten primer so nevronske mreže, vendar se po mehanizmih, prisotnih v možganih, lahko zgledujemo tudi pri metodah spodbujevanega učenja. %TODO: all subsubsections?

Delovanje možganov je kljub številnim raziskavam še vedno precej slabo razumljeno, njihovo računalniško modeliranje pa je v času pisanja še razmeroma mlado področje.
Odkrivanje mehanizmov in vzorcev, ki se pojavijo med delovanjem in učenjem impulznih nevronskih mrež, ter uporaba teh pri modeliranju mehanizmov, za katere vemo, da so prisotni v možganih, predstavlja velik doprinos tako k področju računske nevroznanosti kot tudi psihoanalizi in sorodnim področjem. V neposredni povezavi s psihoanalizo raziskovanje impulznih nevronskih mrež predstavlja raziskovanje temeljnih vprašanj o človeškem dojemanju in delovanju možganov nasploh.

\section{Cilji}
V tej diplomski nalogi razvijemo kompleksnega agenta, ki je zmožen reševati probleme tako s takojšnjimi kot zakasnjenimi nagradami in temelji izključno na impulznih nevronskih mrežah in spodbujevanem učenju. V poglavju \ref{neuron_synapse_modelling} so predstavljeni in ovrednoteni različni modeli bioloških značilnosti nevronov in sinaps. Nato se posvetimo spodbujevanemu učenju, kjer v poglavju 
\ref{sec:rstdp} razvijemo agenta, ki uporablja model sinaptične plastičnosti, odvisne od nagrajevanja in časovne razporeditve impulzov (angl. R-STDP, primer \cite{distalReward}), in se je sposoben naučiti igranja igre \href{https://en.wikipedia.org/wiki/Pong}{Pong}.
%TODO: \cite{conditioningWiki} \ref{sec:reinforcement_learning}. 
Tak agent ni sposoben učenja nalog z zakasnjenimi nagradami, zato v poglavju \ref{sec:td_learning} uporabimo TD učenje. Za ta namen modeliramo nevronska vezja in določene mehanizme iz človeškega dopaminskega sistema. S pomočjo TD modela akter-kritik se naučimo poti do zakasnjene nagrade pri nalogi, kjer se premikamo po mreži. 

\chapter{Pregled področja in sorodnih del}
Na temo impulznih nevronskih mrež v Sloveniji do časa pisanja še ni bila napisana nobena diplomska ali magistrska naloga, doktorska disertacija ali znanstveni članek, kar dodatno motivira pisanje diplomske naloge na to temo. Impulzne nevronske mreže zaradi zahtevnosti učenja (v času pisanja) niso pogosto uporabljene, vse bolj uporabna metoda v umetni inteligenci pa je spodbujevano učenje, ki je tudi prevladujoča in biološko podprta metoda za učenje impulznih nevronskih mrež.

Na temo spobujevanega učenja je na voljo več slovenskih znanstvenih del. Pri spodbujevanem učenju predstavimo svoj sistem kot agenta, ki izvaja aktivnosti nad okoljem, to pa mu kot odziv vrača nagrado in novo stanje okolja. Med drugim je uporabno pri problemih, kot so navigacija in reševanje problemov z roboti, na kar se nanaša članek pod avtorstvom prof. dr. Danijela Skočaja, rednega profesorja na FRI, in dr. Mateja Dobrevskega (\cite{robot}).
Objavljenih je tudi več diplomskih in magistrskih nalog o simuliranih problemih, kot so uporaba spodbujevanega učenja za simulacijo psa ovčarja \cite{shepherdDog}, reševanje problemov sorodnih problemu vozička s palico (\cite{vozicekSPalico}), igranje iger (\cite{predvidevanjeAkcij}) in uporaba TD (angl. \href{https://en.wikipedia.org/wiki/Temporal_difference_learning}{Temporal Difference}) učenja v Monte Carlo preiskovanju dreves (\cite{TDlearning}). V vseh navedenih primerih se zgledujemo po raznolikem procesiranju podatkov iz zunanjega okolja, kjer je v robotiki in podatkih iz resničnega sveta prisoten tudi šum, ki je tako potrebna kot tudi težavna komponenta pri učenju impulznih nevronskih mrež.

Pri spodbujevanem učenju, zlasti v resničnem svetu, imajo impulzne nevronske mreže lahko določene prednosti. Impulzne nevronske mreže namreč naravno upoštevajo časovno komponento in procesirajo sekvenčne podatkovne tokove. Ker so dogodki v teh mrežah v osnovi le propagiranje impulzov sosednjim nevronom v naslednjem časovnem intervalu, je računanje lahko učinkovito in preprosto. Zaradi tega se pojavljajo tudi trdo-ožičene implementacije impulznih nevronskih mrež. V delu \cite{pilotStudy} je raziskana uporaba TD učenja na trdo-ožičeni impulzni nevronski mreži, kjer je končna naloga igranje igre Pong. Tudi v tej diplomski nalogi bo končna naloga enaka, vendar bodo uporabljeni računalniški in ne trdo-ožičeni modeli ter naprednejši učni algoritmi osnovani na spodbujevanem učenju.

V tej diplomski nalogi je poudarek na simulacijah in snovanju algoritmov za spodbujevano učenje na impulznih nevronskih mrežah ter modeliranju različnih bioloških procesov in možganskih nevronskih vezij. Pri tem je dober zgled delo \cite{distalReward}, ki poleg modela nevronov in sinaps vpeljuje še način pripisovanja odgovornosti sinapsam za določeno aktivnost nevronske mreže. V postopku nadgradnje algoritmov učenje poteka tudi na osnovi TD učenja in njegove biološko bolj neposredne implementacije akter-kritik (\cite{actorCritic}). V tem postopku implementiramo dejansko nevronsko vezje odgovorno za nagrajevanje, kot je bilo to raziskano v človeških možganih.


\chapter{Modeliranje nevronov in sinaps}
\label{neuron_synapse_modelling}
Impulzne nevronske mreže so definirane tako z modelom nevrona kot z modelom sinapse, ki nevrone povezujejo. Modelov je sicer veliko, v nadaljevanju pa bosta predstavljena in primerjana dva tipa "integrate and fire" modelov nevronov, glede na njuno uporabnost pri spodbujevanem učenju na impulznih nevronskih mrežah. Prav tako bo predstavljen model sinapse primeren za spodbujevano učenje in prilagojen model, ki bo uporabljen v sistemih razvitih v nadaljevanju. 
\section{Nevronski model}

Nevronski modeli, uporabljeni v tem delu, temeljijo na tokovno gnanih modelih uhajajočega integrirajočega nevrona, pri katerih se membranski potencial spreminja v skladu s pasivnimi električnimi lastnostmi enostavne celične membrane. Dinamika membrane izhaja iz ravnovesja med kapacitivnim nabojem in uhajanjem preko membranske prevodnosti. V simulacijah s simulatorjem NEST ta obnašanja opisujejo naslednji parametri:

\begin{itemize}
    \item \textbf{$E_L$ --- mirovalni membranski potencial} \\
    Električni potencial, proti kateremu membrana pasivno relaksira v odsotnosti od vhodnih tokov.

    \item \textbf{$C_m$ --- membranska kapacitivnost} \\
    Kapacitivnost membrane, ki določa, kako hitro se membranski potencial odziva na vhodne tokove.

    \item \textbf{$\tau_m$ --- membranska časovna konstanta} \\
    Čas, v katerem membrana pasivno integrira tok; definiran kot razmerje med kapacitivnostjo $C_m$ in uhajalsko prevodnostjo $g_L$ (\textit{leakage conductance}),
    ki pa je simulator Nest ne podaja kot neodvisen parameter. $\tau_m$ lahko definiramo tudi kot produkt med kapacitivnostjo in uporom membrane $\tau_m = C_m R_m = \frac{C_m}{g_L}$

    \item \textbf{$t_{ref}$ --- refraktorno obdobje} \\
    Čas, v katerem se nevron po sprožitvi akcijskega potenciala ne more ponovno prožiti.

    \item \textbf{$V_{th}$ --- prag proženja} \\
    Membranski potencial, pri katerem nevron sproži akcijski potencial.

    \item \textbf{$V_{reset}$ --- potencial ponastavitve} \\
    Ponastavitveni membranski potencial.

    \item \textbf{$\tau_{\mathrm{syn,ex}}$ --- sinaptična časovna konstanta (ekscitatorna)} \\
    Čas, ki določa hitrost naraščanja postsinaptičnega toka po proženju. Pri modelu z alfa-jedrom (alfa oblikovan postsinaptični tok) predstavlja čas dviga alfa-funkcije; pri eksponentnem jedru pa čas padca eksponentne funkcije, pri kateri je čas dviga sicer neskončno majhen.

    \item \textbf{$\tau_{\mathrm{syn,in}}$ --- sinaptična časovna konstanta (inhibitorna)} \\
    Čas, ki določa hitrost naraščanja postsinaptičnega toka po proženju, vendar za inhibitorne sinapse.

    \item \textbf{$I_e$ --- zunanji konstantni tok} \\
    Dodani tok, ki modelira stalni zunanji šum.

    \item \textbf{$V_{\min}$ --- spodnja meja membranskega potenciala} \\
    Absolutna spodnja meja za membranski potencial.
\end{itemize}
Membranski potencial $V_m$ se spreminja v odvisnoti od $I_{\text{syn}}$ in ostalih parametrov po naslednji enačbi
\begin{equation}
    \frac{dV_m}{dt}=-\frac{V_m-E_L}{\tau_m}+\frac{I_{\text{syn}}+I_e}{C_m}
\end{equation}.

Skupni tok $I_{\text{syn}}$, ki ga nevron prejme preko vseh sinaps je sestavljen iz excitatorne in inhibitorne komponente.
\[
I_{\text{syn}}(t) = I_{\text{syn, ex}}(t) + I_{\text{syn, in}}(t)
\]

kjer

\[
I_{\text{syn, X}}(t) = \sum_j w_j \sum_k i_{\text{syn, X}}(t - t_j^k - d_j) ,
\]

kjer $j$ teče po ekscitatornih (X = ex) in inhibitornih (X = in) sinapsah z utežmi $w_j$ do presinaptičnih nevronov, $k$ teče po časih impulzov nevrona $j$, $d_j$ pa predstavlja zakasnitev sinapse do nevrona $j$. Postsinaptični tokovi $i_{\text{syn, X}}(t - t_j^k - d_j)$ nevrona $j$ so odvisni od jedra, ki ga uporablja model.

%TODO: “z alpha (\textit{NEST: iaf\_psc\_alpha}) ali exponentno (\textit{NEST: iaf\_psc\_exp}) oblikovanimi postsinaptičnimi tokovi
\subsection{Model z alfa jedrom}
V simulatorju NEST je postsinaptični tok modela z alfa jedrom definiran kot

\[
i_{\text{syn, X}}(t) = \frac{e}{\tau_{\text{syn, X}}} t e^{-\frac{t}{\tau_{\text{syn, X}}}} \Theta(t)
\]

kjer je $\Theta(x)$ enotina stopnica. Postsinaptični tokovi so ob času $\tau_{\text{syn, X}}$ normalizirani v enotski maksimum.

\[
i_{\text{syn, X}}(t = \tau_{\text{syn, X}}) = 1 .
\]

Skupni naboj $q$, ki ga prenese postsinaptični tok je tako odvisen od sinaptične časovne konstante in je izračunan po naslednji enačbi
\[
q = \int_0^{\infty} i_{\text{syn, X}}(t) dt = e \tau_{\text{syn, X}} .
\]


\subsection{Model z eksponentnim jedrom}
V simulatorju NEST je model z eksponentim jedrom (iaf\_psc\_exp) definiran po sistemu diferencialnih enačb prvega reda, ki jih navaja \cite{expModel}. Postsinaptični tok $y(t)$ se spreminja po sistemu
\begin{align}
    \frac{dx}{dt}&=\frac{z}{\tau_{rec}}-ux\delta({t-t_{sp}}) \\
    \frac{dy}{dt}&=-\frac{y}{\tau_I}+ux\delta({t-t_{sp}}) \\
    \frac{dz}{dt}&=\frac{y}{\tau_I}-\frac{z}{\tau_{rec}}
\end{align}
kjer $t_{sp}$ predstavlja čas presinaptičnega impulza, $\tau_I$ čas sinaptičnega odtekanja,
$\tau_{rec}$ čas povrnitve sinaptičnih virov,
$u$ delež sinaptičnih virov porabljenih pri impulzu in
$\delta(t-t_{sp})$ delta porazdelitev, za instantne posodobitve ob impulzih.

Če opazujemo samo speminjanje $y(t)$ skozi čas brez novih impulzov, bo $\delta(t-t_{sp})=0$ in se diferencialna enačba za $y$ poenostavi v
\begin{equation}
    \frac{dy}{dt}=-\frac{y}{\tau_I}
\end{equation}
rešitev te diferencialne enačbe je tako
\begin{equation}
    y(t)=y_0 e^{-t/\tau_I}
\end{equation}
kjer vidimo, da je jedro res exponentna funkcija z začetkom v $y_0$. Skok potenciala po impulzu je definiran z utežjo sinapse $w$, postsinaptični tok pa je sam po sebi definiran samo s hitrostjo padanja funkcije $\tau_I$, ki pa je v simulatorju NEST predstavljen s $\tau_{\text{syn, X}}$.

\[
i_{\text{syn, X}}(t) = e^{-\frac{t}{\tau_{\text{syn, X}}}} \Theta(t)
\]
\\
\\
Skupni naboj $q$, ki ga prenese postsinaptični tok je tako izračunan po naslednji enačbi
\[
q = \int_0^{\infty} i_{\text{syn, X}}(t) dt = \tau_{\text{syn, X}} .
\]

\begin{figure}[htb]
\begin{center}
\includegraphics[width=1.0\textwidth]{neuron_models/PSCs}
\end{center}
\caption{Postsinaptični tok modela z alfa in eksponentim jedrom}
\label{pic1}
\end{figure}

\subsection{Izbira modela nevrona}
V sistemih, ki jih bomo implementirali v nadaljevanju skušamo skušamo pri modeliranju mehanizmov v človeških možganih uporabiti čimmanj poenostavitev ali posplošitev za kar je bolj primeren model
nevrona z alfa jedrom, ki ima biološko bolj realistično obliko postsinaptičnega toka. V nadaljevanju sta kljub temu uporabljena oba modela, saj se zaradi različnih oblik postsinaptičnega toka za spodbujevano učenje odvisno od nagrade bolje obnese model z esponentnim jedrom.

Za nas sta najpomembnejši razlika v količini prenesenega naboja $q$ in, kot je opisano v poglavju spodbujevano učenje z R-STDP, razlika v varianci frekvence impulzov zaradi zunanjega šuma in razlik v utežeh sinaps. Količina prenesenega naboja $q_{\text{alfa}}$ je pri alfa jedru večja od prenesenega naboja pri eksponentnem jedru $q_{\text{exp}}$ za faktor $\frac{q_{\text{alfa}}}{q_{\text{exp}}} = e$. To razliko zlahka prilagodimo z nižjimi vrednostmi uteži sinaps. Razlika v varianci frekvenc impulzov je posledica daljšega časovnega intervala pri alfa jedru napram eksponentnem, kjer je postsinaptični tok blizu maksimalne vrednosti napram eksponentnem. Zaradi tega bodo zaporedni postsinaptični impulzi skozi čas precej bolj prekrivni, pri intergriranju različnih postsinaptičnih tokov sozi čas pa pride do učinka nizko prepustnega filtra. Tako so nenadne spremembe v amplitudi skupnega toka na vhodu v postsinaptični nevron ublažene. Posledica so manjše razlike v frekvenci impulzov postsinaptičnega nevrona, če imamo na vhodu sinapse različne uteži, učinek pa je še bolj opazen ob dodanem šumu. Pri alfa jedru bo namreč šum povzročil manj variance v frekvenci impulzov postsinaptičnega nevrona, kot pri eksponentnem jedru.
\\
\\
Primerjamo oba modela preko 5 postsinaptičnih nevronov v katere injeciramo poissonski šum. %TODO: link
Da dosežemo karseda enako osnovno frekvenco impulzov postsinaptičnih nevronov pri alfa in eksponentnem jedru je utež sinapse za faktor $e$ manjša od uteži sinaps do nevronov z eksponentnim jedrom.

\begin{table}[ht]
\centering
\caption{Parametri simulacije uporabljeni pri primerjavi modelov nevronov.}
\label{tab:simulation_parameters_si}
\begin{tabular}{ll}
\hline
\textbf{Parameter} & \textbf{Vrednost} \\
\hline
Število postsinaptičnih nevronov & 5 \\
Trajanje simulacije & 5000 ms \\
$C_m$ & 250.0 pF \\
$\tau_m$ & 20.0 ms \\
$E_L$ & 0.0 mV \\
$V_\text{th}$ & 20.0 mV \\
$V_\text{reset}$ & 0.0 mV \\
$t_\text{ref}$ & 2.0 ms \\
$\tau_\text{syn,ex}$ & 5.0 ms \\
Utež sinapse (Exp PSC) & 25.0 \\
Utež sinapse (Alpha PSC) & 25.0 / $e \approx 9.20$ \\
Frekvenca Poissonovega šuma & 8000 Hz na nevron \\
\hline
\end{tabular}
\end{table}
\begin{table}[ht]
\centering
\caption{Povzetek statistike medimpulznih intervalov nevronov z alfa in exponentnim jedrom. Povprečje in standardni odklon sta izračunana na vseh postsinaptičnih nevronih.}
\label{tab:isi_summary}
\begin{tabular}{lcc}
\hline
Jedro & Povprečje (ms) & Varianca (ms$^2$) \\
\hline
Exponentno & \(7.846 \pm 0.021\) & \(\mathbf{0.402 \pm 0.028} \) \\
Alfa       & \(7.800 \pm 0.023\) & \(\mathbf{0.270 \pm 0.006} \) \\
\hline
\end{tabular}
\end{table}

\section{STDP Sinaptični model}
Sinapse, ki so bile uporabljene v nalogi temeljijo v celoti na modelu odvisnem od nagrade in časovne razporeditve impulzov pre in postsinaptičnih nevronov (\textit{NEST: stdp\_dopamine\_synapse}), vendar v sistemih, ki jih razvijemo v nalogi uporabljamo prilagoditev te sinapse, ki ima sled odgovornosti (\textit{angl. eligibility trace}) zamaknjeno v času.

V sistemih, ki bodo implementirani v tej nalogi bomo uporabljali prilagojeno sinapso s plastičnostjo odvisno od nagrade in časovne razporeditve impulzov (\textit{angl. R-STDP synapse}).
STDP prilagaja sinaptične uteži glede na relativni čas impulzov pre- in postsinaptičnih nevronov. V svoji klasični obliki STDP uresničuje Hebbov %TODO: link
princip:
%TODO: pre- in post-

\begin{quote}
``Nevroni, ki se skupaj prožijo, se povežejo.''
\end{quote}
Če se presinaptični nevron sproži \textbf{pred} post-sinaptičnim (\(\Delta t > 0\)), se sinapsa \textbf{okrepi} (potencira). Če se pre-sinaptični nevron sproži \textbf{po} post-sinaptičnem (\(\Delta t \leq 0\)), se sinapsa \textbf{oslabi} (depresira).

Matematično je to opisano s funkcijo okna STDP:

\[
\mathrm{STDP}(\Delta t) =
\begin{cases}
A_+ e^{-|\Delta t|/\tau_+}, & \text{če } \Delta t > 0 \text{ (pre-sinaptični pred post-sinaptičnim)} \\
A_- e^{-|\Delta t|/\tau_-}, & \text{če } \Delta t \le 0 \text{ (post-sinaptični pred pre-sinaptičnim)}
\end{cases}
\]

kjer so:
\begin{itemize}
    \item \(A_+\) in \(A_-\) multiplikatorja za potenciranje in depresijo,
    \item \(\tau_+\) in \(\tau_-\) časovne konstante, ki določajo okno vpliva časovnih razlik.
\end{itemize}

\subsubsection*{Dopaminska modulacija}

Pri neuromodulirani STDP dopaminska koncentracija \(n\) modulira velikost in smer sinaptične plastičnosti tj. velikost in predznak posodobitve uteži povezave. Sinaptična dinamika je opisana z naslednjimi enačbami:

\[
\begin{aligned}
\dot{w} &= c \, (n - b) \\
\dot{c} &= -\frac{c}{\tau_c} + \mathrm{STDP}(\Delta t) \, \delta(t - s_{\text{pre/post}}) C_1 \\
\dot{n} &= -\frac{n}{\tau_n} + \frac{\delta(t - s_n)}{\tau_n} C_2
\end{aligned}
\]

kjer so:
\begin{itemize}
    \item \(w\) --- sinaptična utež,
    \item \(c\) --- \emph{eligibility trace} (spremlja pare sproženih pre in postsinaptičnih nevronov),
    \item \(n\) --- dopaminska koncentracija/sled,
    \item \(b\) --- bazalna dopaminska koncentracija,
    \item \(s_{\text{pre/post}}\) --- čas pre- ali post-sinaptičnega impulza,
    \item \(s_n\) --- čas impulzov dopaminskih nevronov,
    \item \(C_1, C_2\) --- konstante,
    \item \(\tau_c, \tau_n\) --- časovne konstante odtekanja \emph{eligibility} in dopaminskih sledi.
\end{itemize}

\begin{figure}[H]
\begin{center}
\includegraphics[width=1.0\textwidth]{neuron_models/RSTDP}
\end{center}
\caption{\textit{eligibility} sled $c$, dopaminska sled $n$ in evolucija sinaptične uteži pri presinaptičnih impulzih pri $[10.0, 30.0]$ ms in postsinaptičnih inpulzih pri $[12.0, 32.0]$ ms, simulirane preko $150$ ms pri R-STDP sinapsi z  $\tau_c = 50.0$ ms, $\tau_{c,\mathrm{delay}} = 50.0$ ms, $\tau_n = 10.0$ ms, $\tau_\mathrm{plus} = 10.0$ ms, $b = 0.0$, $A_\mathrm{plus} = 0.2$, $A_\mathrm{minus} = 0.2$, in sinaptično zakasnitvijo $0.5$ ms.}
\label{pic2}
\end{figure}
\newpage

V poglavju \textbf{R-STDP učenje} %TODO: link
bomo R-STDP sinapso uporabili tako, da bomo ob pravilni akciji agenta pri spodbujevanem učenju povezave, ki so bile najbolj odgovorne za izbiro akcije okrepili. To bomo dosegli tako, da za vse povezave hkrati povišamo koncentracijo dopamina, pri tem pa bodo najmočnejše povezave, ki bodo povzročile največ kavzalnih parov pre in postsinaptičnih impulzov imele najvišji eligibility in bodo tako najbolj okrepljene. Agent bo ob prihodu v določeno stanje izbral naslednjo akcijo, kjer bo nagrada na voljo šele ob prihodu v naslednje stanje, v kolikor je to stanje pravilno, zato hočemo posodobiti povezave, ki so bile odgovorne za akcijo, ki nas je do tega stanja pripeljala. Koncentracijo dopamina bomo povišali za čas določenega intervala ob prihodu v nagrajeno stanje, kjer pa bi lahko potemtakem posodabljali že povezave, ki so aktivne v novem stanju. Da se temu izognemo bomo onemogočili posodaljanje sinaps zaradi nagrad, ki pridejo prehitro znotraj določenega intervala $\tau_{c, \text{delay}}$.
Celotno \textit{eligibility} sled bomo tako premaknili za $\tau_{c, \text{delay}}$

\begin{figure}[H]
\begin{center}
\includegraphics[width=1.0\textwidth]{neuron_models/RSTDP_delayed}
\end{center}
\caption{\textit{eligibility}  sled $c$, dopaminska sled $n$ in evolucija sinaptične uteži pri presinaptičnih impulzih pri $[10.0, 30.0]$ ms in postsinaptičnih inpulzih pri $[12.0, 32.0]$ ms, simulirane preko $150$ ms pri R-STDP sinapsi z  $\tau_c = 50.0$ ms, $\tau_{c,\mathrm{delay}} = 50.0$ ms, $\tau_n = 10.0$ ms, $\tau_\mathrm{plus} = 10.0$ ms, $b = 0.0$, $A_\mathrm{plus} = 0.2$, $A_\mathrm{minus} = 0.2$, in sinaptično zakasnitvijo $0.5$ ms.}
\label{pic2}
\end{figure}


\chapter{Spodbujevano učenje na impulznih nevronskih mrežah}
\label{sec:reinforcement_learning}
\colorbox{Apricot}{%
  \parbox{0.9\linewidth}{%
    \textbf{
        Verjetno potrebno več uvoda v spodbujevano učenje. Tu morda lahko prikažemo še par osnovnih mehanizmov sinaps, na primer asociacije med nevroni, 
        ki se pogosto prožijo in uporaba tega za primer klasičnega pogojevanja tudi brez nagrade.
    }%
  }%
}

\newpage
\section{R-STDP učenje}
\label{sec:rstdp}
Imamo klasičnega agenta spodbujevanega učenja, ki dobi informacijo o zunanjem okolju preko stimulacije vhodnih nevronov, nato pa kot odziv na trenutno stanje izbere akcijo, ki zunanje okolje spremeni. V kolikor smo se znašli v nagrajenem stanju bomo agenta nagradili z nagrado. Preko nagrajevanja in interagiranja z okoljem se bo agent naučil akcij, ki privedejo do nagrade v določenem stanju.
\\
\\
Za začetek bo naš agent sestavljen iz $N_{in}$ vhodnih nevronov, ki predstavljajo možna stanja in bodo povezani z $N_a$ nevroni na izhodu. Vhod in izhod sta povezana po režimu \textit{all-to-all}, kjer so vsi nevroni vhoda povezani z vsemi nevroni izhoda. Vzvratnih povezav tu ne dopuščamo. Za mehanizme ob prisotnosti vzvratnih povezav glej poglavje %TODO: link
\textbf{Rekurenčne povezave}. Ob prihodu v določeno stanje ustrezen vhodni nevron stimuliramo tako, da ta se ta za čas $200$ ms proži s frekvenco $100$ Hz. Akcijo izberemo na koncu intervala, glede na aktivnost izhodnih nevronov, ki predstavljajo možne akcije. Med njimi izberemo nevron, ki je tekom trenutnega stanja imel najvišje število impulzov. V kolikor vstopimo v nagrajeno stanje, bomo $N_{\text{dopa}}$ dopaminskih nevronov stimulirali s $600$ pA tokom. Dopaminski nevroni ob impulzu projecirajo dopamin enakomerno med vse povezave med vhodnimi in izhodnimi nevroni.
\\
\\
Nagrada, ki jo neposredno predstavlja aktivnost dopaminskih nevronov bo vedno velčja ali enaka $0$, kar pomeni, da morajo povezave, ki predstavljajo izbiro določene akcije v določenem stanju med seboj tekmovati za prevlado. Pri tem moramo omogočiti dovolj veliko varianco med impulzi izhodnih nevronov predvsem v začetni fazi, ko so vse povezave približno enako velike. V nasprotnem primeru bodo vse povezave posodobljene za približno enako vrednost glede na RSTDP. 
\newpage
Varianco med impulzi pri enakih povezavah dosežemo z zunanjim šumom. Biološko najbolj realističen je poissonski šum, saj prestavlja impulze nevronov, zaradi zunanjih stimulusov nepovezanih s trenutnim stanjem.
\begin{equation}
    P(k \text{ impulzov v }\Delta t) = \frac{(\lambda \Delta t)^ke^{-\lambda\Delta t}}{k!},\ \ \ k=0,1,2...
\end{equation}
Naš agent bo uporabljal model nevrona z eksponentim jedrom, saj tako poissonski šum povzroči večjo varianco izhodnih nevronov kot model z alfa jedrom, kot demonstrirano v poglavju %TODO: link
\textbf{Izbira modela nevrona}. V začetni fazi bodo tako akcije v večini izbrane naključno, ob majhnem številu izhodnih impulzov pa bo razlika variance relativno večja kot pri višji aktivnosti izhodnih nevronov. Tako bo v kasnejših fazah učenja izbira akcije čedalje manj odvisna od šuma.
\begin{figure}[htbp]
\begin{center}
\includegraphics[width=1.0\textwidth]{rstdp/competition}
\end{center}
\caption{
Primer učenja na preprosti nalogi s tremi stanji. Prehod v vsako stanje je nakjučno, v vsakem stanju pa je samo ena izbira akcije nagrajena. V stanju 0 (input neuron 0) je pravilna akcija 0 (motor neuron 0), v stanju 1 akcija 1, v stanju 2 akcija 2. Razvidna je prevlada pravilnih sinaps in višanje divergence v sinapsah skozi čas ter višanje povprečne nagrade tekom učenja. V simulaciji uporabljamo privzete NEST parametre za nevrone tipa \textit{iaf\_psc\_exp} ter zakasnjene dopaminsko modulirane sinapse s parametri $W_{\min} = 500$, $W_{\max} = 2000$, $\tau_c = 5\,\mathrm{ms}$, $\tau_{c,\mathrm{delay}} = 200\,\mathrm{ms}$, $\tau_n = 10\,\mathrm{ms}$, $\tau_+ = \tau_- = 20\,\mathrm{ms}$, $b = 0.1$, $A_+ = 0.7$, $A_- = 0.3$ ter sinaptično zakasnitev $0.5\,\mathrm{ms}$, poissonski šum z $\lambda = 1000$ in utežjo sinaps $w_{\text{poisson}} = 100$. Sinapse med vhodnimi in izhodnimi nevroni so inicializirane na $w_{\text{motor}} \sim \mathcal{N}(1300, 1)$.}
\label{competition}
\end{figure}
\newpage
\subsection{Igra Pong}
V nadaljevanju bomo R-STDP predstavili na agentu, ki igra \href{https://en.wikipedia.org/wiki/Pong}{\textit{Pong}}. R-STDP učenje je kratkovidno, kjer se bomo naučili akcij, samo če nagrada sledi nemudoma, ne pa, če je nagrada zakasnjena. Za zakasnjene nagrade uporabljamo TD (\textit{angl. Temporal Difference}) učenje, ki ga implementiramo v poglavju \textbf{TD učenje in model actor-critic}. Igra Pong v osnovi zahteva veliko predvidevanja, vendar lahko igranje igre poenostavimo v obliko, ki se jo lahko naučimo z R-STDP učenjem. Igro bomo v nadaljevanju definirali tako, da ima žogica stalno hitrost, določeno smer in pozicijo v x, y ravnini. Na levi strani igrišča bo naš agent premikal platformo v vertikalni smeri na desni strani pa je stena od katere se prožno odbije žogica. V kolikor bi v učenje vključili predvidevanje, bi morali stanja agenta definirati kot kartezični produkt x,y pozicije žogice, njene smerji in y pozicije platforme, lahko pa problem poenostavimo v problem sledenja žogici enako kot v delu \cite{pilotStudy}, kjer agent izira željeno ciljno točko platforme. Tako stanja kot akcije agenta so tako diskretizirane možne y pozicije žogice. Stanje je nagrajeno s stimulacijo dopaminskih nevronov s tokom $I_{R}$, ki je sorazmeren razliki med nagrado $R_b$ izračunani glede na oddaljenost željene pozicije $j$ od trenutne y pozicije žogice $j$ in povprečno nagrado $\bar{R}_i$ v iteraciji $i$. S pomočjo povprečne nagrade omejimo krepitev sinaps v kolikor te ne izboljšajo trenutne politike.

\begin{align}
R_b &= \begin{cases}
    1-|j-k| \cdot 0.3 & \text{if} \ |j-k|\leq3, \\
    0 & \text{otherwise}.
    \end{cases} \\
I_{R} &= \max(R_b-\bar{R}_i, 0) \cdot 600 \text{ pA}
\end{align}

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=0.6\textwidth]{figures/pong_setup}
\end{center}
\caption{Grafična predstavitev agenta in okolja (\cite{pilotStudy})}
\label{pic5}
\end{figure}

Pričakujemo, da bodo sorazmerno oddaljenosti v posameznih stanjih prevladale sinapse, ki iz vhodnega nevrona vodijo do akcij okrog istoležnega izhodnega nevrona. Polje bomo po y osi diskretizirali na 20 stanj.

\begin{figure}[H]
\begin{center}
\includegraphics[width=1.0\textwidth]{rstdp/rstdp-pong/learning}
\end{center}
\caption{Graf povezav med vhodnim nevronom, ki predstavlja $y=5$ pozicijo in 20 izhodnimi nevroni, kjer tekom učenja prevladuje motorični nevron 5. Motorična nevrona 4 in 6 pa sta druga po vrsti. Za simulacijo smo uporabili enake parametre kot pri sliki \ref{competition} }
\label{pic6}
\end{figure}
\newpage
\subsubsection{Rezultati}
Učenje spremljamo preko povprečne nagrade prejete ob prehodih stanj, ki se bliža maksimalni nagradi $R_{\text{max}}=1.0$.
\begin{figure}[htbp]
\begin{center}
\includegraphics[width=1.0\textwidth]{rstdp/rstdp-pong/mean_reward}
\end{center}
\caption{Povprečna nagrada $\bar{R}_i$ tekom 2000 iteracij po 200ms}
\label{pic7}
\end{figure}
\\
\\
\colorbox{Apricot}{%
  \parbox{0.9\linewidth}{%
    \textbf{
      Vključi še graf dolžine neprekinjene igre (do zgrešitve) kot posledica učenja.
    }%
  }%
}
\\
\\
Kot že omenjeno je takšno učenje učinkovito samo pri nagradah, ki niso oddaljene, oziroma drugače povedano, se agent ne bo naučil potencialne poti skozi različna nenagrajena stanja, da pride do končne nagrade. To je vidno pri nalogi iskanja oddaljene nagrade v mreži, kjer se agent lahko premika levo, desno, gor in dol. Agent se bo namreč naučil prehoda samo iz stanj neposredno ob cilju.
\\
Ob učenju bomo agenta nagradili ko preide v končno stanje in ga po tem postavili v naključno stanje. Trenutno politiko agenta bomo predstavili s puščicami s smerjo, ki jo določa normaliziran vektor $\hat{x}_i$ v vsakem od stanj $i$, ki predstavljajo preferenco akcije glede na medsebojne razlike v utežeh sinaps.

\[
\begin{aligned}
    \overrightarrow{x_i} &= \sum_{j=0}^{3} w_{ij} \cdot \overrightarrow{d}_j, \\
    L_i &= ||\overrightarrow{x_i}||, \\
    \hat{x}_i &= \begin{cases} \frac{\overrightarrow{x_i}}{L_i} & \text{if } L_i > 0 \\
        0 & \text{otherwise}
    \end{cases},
\end{aligned}
\]

\noindent
kjer je \(w_{ij}\) utež sinapse iz vhodnega nevrona \(i\) do izhodnega nevrona \(j\) in $\overrightarrow{d}_j$ smerni vektor, ki predstavlja akcijo izhodnega nevrona \(j\)
\[
\overrightarrow{d}_0 = (0,1), \quad
\overrightarrow{d}_1 = (0,-1), \quad
\overrightarrow{d}_2 = (-1,0), \quad
\overrightarrow{d}_3 = (1,0).
\]

Za prikaz ''samozavesti" pri izbiri akcije v stanju $i$ kot rezultat učenja, bomo polja ustrezno obarvali glede na maksimalno razliko med utežmi med vhodnim nevronom $i$ in vsakim od izhodnih nevronov.

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=0.6\textwidth]{rstdp/rstdp-gridworld/best}
\end{center}
\caption{Prikaz politike po 500 iteracijah po 200ms. Končno stanje je obarvano z zeleno.}
\label{pic8}
\end{figure}

Rezultat potrjuje, da se agent ni sposoben naučiti poti do nagrade iz poljubnega stanja, vendar samo iz stanj neposredno ob nagradi.

\section{TD učenje in model actor-critic}
\label{sec:td_learning}
Časovno razlikovalno učenje (angl. Temporal Difference Learning, TD) je metoda spodbujevanega učenja, ki posodablja oceno vrednosti stanj ali parov stanje–akcija sproti, med interakcijo z okoljem.

Osnovna posodobitvena enačba za vrednostno funkcijo stanja pri TD(0) je

\[
V(s_t) \leftarrow V(s_t) + \alpha\,\delta_t,
\]

kjer je \(\alpha\) hitrost učenja, TD-napaka \(\delta_t\) pa je definirana kot

\[
\delta_t = r_{t+1} + \gamma V(s_{t+1}) - V(s_t).
\]

V izrazu je \(r_{t+1}\) nagrada ob prehodu iz stanja \(s_t\) v stanje \(s_{t+1}\), faktor \(\gamma \in [0,1]\) pa določa relativno težo prihodnjih nagrad. TD-napaka predstavlja razliko med izboljšano napovedjo vrednosti in prejšnjo oceno.
\\
\\
\colorbox{Apricot}{%
  \parbox{0.9\linewidth}{%
    \textbf{
      Verjetno daljši uvod v TD učenje?
    }%
  }%
}
\subsection{Model actor-critic}
TD učenje bomo implementirali z modelom akter-kritik (\textit{angl. actor-critic}), po zgledu \cite{actorCritic} na nalogi z mrežo. Za razliko od sistema, ki ga predstavijo Wiebke P, et al. bomo za sinapso uporabili našo zakasnjeno RSTDP, ki omogoča pripisovanje odgovornosti povezavam poljubno v preteklost, kar je pomembno pri učenju, kjer stanja niso definirana v diskretnih intervalih. Poleg tega upoštevamo tako kavzalne kot tudi antikavzalne impulze, po pravilu RSTDP med vsemi pari v zgodovini impulzov (\textit{all-to-all} namesto \textit{next-neighbor} \colorbox{Apricot}{\textbf{razloži}}). Sistem, ki ga bomo implementirali je tudi manjši glede na število nevronov, za višjo hitrost simulacije. Stanja bomo razdelili v intervale dolžine 200ms ob prehodu stranj pa bomo vhodne nevrone stimulirali enako kot pri RSTDP. %TODO: link 
Pri prehodu med stanji lahko določen del stimuliranih nevronov iz prejšnjega stanja postane asociiranih (\colorbox{Apricot}{\textbf{pokaži}}) z akcijo naslednjega stanja, kar v osnovi ni napačno in je posledica uporabe RSTDP sinapse, vendar bomo za bolj učinkovito učenje med prehodi stanj prekinili stimulacijo 50ms pred stimulacijo novega stanja, saj so za našo nalogo stanja med seboj neodvisna. Za določeno stanje ni važno v katerem stanju smo se nahajali prej.
\\
\colorbox{Apricot}{\textbf{tu verjetno potrebna bolj podrobna razlaga...}}
\\
\\
Model akter-kritik je sestavljen iz dveh delov, akterja - dopaminsko moduliranega RSTDP dela, kot smo ga že implementirali in pa kritika, ki ocenjuje vrednost trenutnega stanja. Celoten model je navdihnjen po dopaminskem sistemu prisotnem v človeških možganih oziroma bolj konkretno bazalnih ganglijih. %TODO: link
Bazalni gangliji so skupina jedrov v možganih, ki igrajo ključno vlogo pri nadzoru gibanja, učenju akcij in odločanju, poleg tega pa realizira obliko TD učenja. Akter-kritik je poenostavitev in abstrakcija resničnih mehanizmov v možganih, vendar uporablja podobne mehanizme. V bazalnih ganglijih in modelu akter-kritik, kot ga predstavlja Wiebke P, et al. razlikujemo dve glavni poti: direktno in indirektno pot, ki vodita iz \textit{striatuma} do dopaminergičnih nevronov. Direktna pot je zakasnjena inhibitorna pot, ki poteka neposredno od striatuma do dopaminergičnih nevronov,
indirektna pot pa je inhibitorna do \textit{ventralnega palliduma}, posebne skupine nevronov, ki inhibira aktivnost dopaminergičnih nevronov. Ob prisotnosti neke osnovne od 0 različne frekvence nevronov \textit{ventralnega palliduma} bo tako indirektna pot imela ekscitatoren učinek na dopaminergične nevrone. Indirektna in direktna povezava delujeta konkurenčno. Indirektna pot ima minimalen zamik in aktivnost striatuma v trenutnem stanju neposredno preslika na povišano aktivnost dopaminergičnih nevronov. Hkrati v času nahajanja v trenutnem stanju direktna povezava inhibira dopaminergične nevrone sorazmerno z aktivnostjo striatuma, kot je ta bila v prejšnjem stanju, zaradi zakasnitve. Indirektna in direktna povezava tako skupaj računata TD-napako $\delta_t$, ki bo v trenutnem stanju glede na izračunan estimat vrednosti trenutnega stanja okrepila sinapse prejšnjega stanja, ki so izbrale aktivnost, ki nas je pripeljala v to stanje. Povprečna teža sinaps med vhodnim nevronom $i$ in striatumom tako neposredno prestavlja vrednost stanja $i$. Ob prehodu iz stanja z visoko povprečno utežjo sinaps do striatuma v stanje z nizko, bo direktna povezava prevladala in bodo dopaminergični nevroni inhibirani in obratno. V primeru, da se premaknemo v stanje s približno isto povprečno utežjo povezave do striatuma pa se bosta direktna in indirektna povezava izničili, dopaminergični nevroni pa se bodo prožili po frekvenci, ki jo definira externi poissonski šum.

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=0.6\textwidth]{figures/basal_ganglia}
\end{center}
\caption{Direktna in indirektna pot v basalnih ganglijih}
\label{pic8}
\end{figure}

Model, kot ga predlaga Wiebke P, et al. funkcionalno združuje \textit{substantio nigro} in \textit{talamus} kot dopaminergični nevroni in signal do povezav med vhodom in striatumom in vhodom in izhodnimi motoričnimi nevroni. Ventralno \textit{globusu pallidusu} se nahaja \textit{ventral pallidum}, ki prestavlja del pallidusa povezan z pričakovanjem nagrade in odločanjem. Wiebke P, et al. tako za nevrone na indirektni poti uporablja ta izraz.
\\
\\
Kot akter bomo v nadaljevanju uporabili RSTDP del kot smo ga implementirali prej.  Od implementacije Wiebke P, et al. se poleg sinapse naša implementacija razlikuje tudi v načinu izbire stanja, kjer mi za izbrano stanje vzamemo stanje z maksimalnim številom impulzov za razliko od izbire prvega izhodnega nevrona, ki se je sprožil kot rezultat stimulacije v trenutnem stanju. Ta način bolj direktno okrepi povezave odgovorne za izbrano aktivnost, saj po prvem izhodnem impulzu inhibira vse ostale izhodne nevrone, kar izniči njihovo \textit{eligibility} sled. Tako ni potrebe po tekmovanju sinaps, kot pri naši metodi, vendar moramo preveriti impulze izhodnih nevronov v vsakem koraku simulatorja. V primeru simulatorja NEST je to vsakih 0.1ms, kar pa je problematično, saj simulator teče v C++ zaledju, ki ga zapustimo takoj ko prekinemo simulacijo. Tako je bistvena razlika med tem, da 100krat poženemo ukaz \texttt{nest.Simulate(0.1)} ali enkrat \texttt{nest.Simulate(10)}. V akterju bomo zaradi razlogov navedenih v poglavju \textbf{RSTDP učenje} %TODO: link
uporabljali model nevrona z eksponentnim jedrom, v kritiku, pa bomo poskusili uporabiti biološko bolj realistične nevrone z alfa jedrom. Ker bodo vhodni nevroni akterju in kritiku skupni, bomo med vhodnimi nevroni in izhodnimi nevroni dodali dodaten nivo nevronov, ki bo višjo frekvenco potrebno za stimulacijo nevronov kritika z alfa jedrom znižal na frekvenco ustrezno za nevrone akterja z eksponentnim jedrom. S tem smo tudi zmanjšali povezanost dveh delov, kar olajša iskanje ustreznih hiperparametrov, poleg tega pa lahko tudi šum za potrebe RSTDP učenja dovajamo ločeno od kritika.
\\
\\
\begin{figure}[htbp]
\begin{center}
\includegraphics[width=1.0\textwidth]{figures/dipl_TD_model}
\end{center}
\caption{Prikaz implementiranega aktor-kritik sistema}
\label{pic8}
\end{figure}
\newpage
\subsection{Izbira parametrov}
Parametri so bili izbrani eksperimentalno in se ne ozirajo na biološko točnost. Ob spreminjanju velikosti posameznih skupin nevronov moramo pri izbiri parametrov paziti na ohranjanje osnovne frekvence dopaminergičnih nevronov in da sta inhibicija in ekscitacija zaradi direktne in indirektne povezave v ravnovesju. Redukcija frekvence, ki jo opravlja plast nevronov med vhodnimi in izhodnimi, mora biti dovolj velika, da bo pri osnovih utežeh sinaps med srednjo plastjo in izhodnimi nevroni šum omogočil učenje, kot je to razloženo v poglavju \textbf{R-STDP učenje}. %TODO: link
Navedene so konstante in parametri implementiranega modela. Parametri, ki niso prikazani v tabeli imajo privzeto vrednost NEST simulatorja.
\begin{table}[htbp]
\caption{Parametri simulacije}
\begin{tabular}{lll}
\textbf{Simbol} & \textbf{Pomen} & \textbf{Vrednost} \\ \hline
% ------- Simulation constants -------
POLL\_TIME & Čas simulacije na iteracijo & 200 \\ \hline
\(f(s_{\text{in}, i})\) & frekvenca stimulacije vhodnega nevrona $i$ & $100$ Hz \\ \hline
\(n_{\text{critic}}\) & Število nevronov v skupinah nevronov kritika & 8 \\ \hline
\end{tabular}
\end{table}
\\
%TODO: number of neurons
\begin{table}[H]
\begin{tabular}{lll}
\textbf{Simbol} & \textbf{Pomen} & \textbf{Vrednost} \\ \hline
\thead[l]{\bfseries Parametri skupin \\
\bfseries nevronov kritika} \\
tip & Tip modela nevrona & \textit{iaf\_psc\_alpha} \\ \hline
\(C_{m,\text{in}}\) & Membranska kapacitivnost & 250.0 pF \\ \hline
\(\tau_{m,\text{in}}\) & Časovna konstanta membrane & 10.0 ms \\ \hline
\(V_{\text{reset,in}}\) & Potencial ponastavitve & 0.0 mV \\ \hline
\(V_{\text{th,in}}\) & Prag proženja & 20.0 mV \\ \hline
\(t_{\text{ref,in}}\) & Refraktorna doba & 0.5 ms \\ \hline
\(\tau_{\text{syn,ex,in}}=\tau_{\text{syn,in,in}}\) & \makecell[l]{Ekscitatorna in inhibitorna \\ sinaptična konstanta} & 2 ms \\ \hline
\(\tau_{\text{-,a}}\) & Negativna STDP konstanta & 20.0 ms \\ \hline
\(V_{m,\text{in}}\) & Začetni membranski potencial & 0.0 mV \\ \hline
\(E_{L,\text{in}}\) & Mirovalni potencial & 0.0 mV \\ \hline
\\
\thead[l]{\bfseries Parametri motoričnih \\
\bfseries nevronov} \\
tip & Tip modela nevrona & \textit{iaf\_psc\_exp} \\ \hline
\(C_{m,a}\) & Membranska kapacitivnost motornih nevronov & 250.0 pF \\ \hline
\(\tau_{m,a}\) & Časovna konstanta membrane & 10.0 ms \\ \hline
\(V_{\text{reset,a}}\) & Potencial ponastavitve & 0.0 mV \\ \hline
\(V_{\text{th,a}}\) & Prag proženja & 20.0 mV \\ \hline
\(t_{\text{ref,a}}\) & Refraktorna doba & 0.1 ms \\ \hline
\(\tau_{\text{syn,ex,a}}=\tau_{\text{syn,in,a}}\) & \makecell[l]{Ekscitatorna in inhibitorna \\ sinaptična konstanta} & 2 ms \\ \hline
\(\tau_{\text{-,a}}\) & Negativna STDP konstanta & 20.0 ms \\ \hline
\(V_{m,a}\) & Začetni membranski potencial & 0.0 mV \\ \hline
\(E_{L,a}\) & Mirovalni potencial & 0.0 mV \\ \hline
\end{tabular}
\caption{Parametri nevronov}
\end{table}
\\
\begin{table}[H]
\begin{tabular}{lll}
\textbf{Simbol} & \textbf{Pomen} & \textbf{Vrednost} \\ \hline
\\
\thead[l]{\bfseries Parametri sinaps med \\
\bfseries vhodnimi in \\
\bfseries vhodnimi motoričnimi \\
\bfseries nevroni} \\ \hline
tip & Tip sinapse & \makecell[l]{Privzeta konstantna \\ NEST sinapsa} \\ \hline
\(w_{\text{in}\to\text{in, motor}}\) & \makecell[l]{Uteži sinaps med \\ vhodnimi in vhodnimi \\ motoričnimi nevroni} & 120 \\ \hline
\\
\thead[l]{\bfseries Parametri sinaps med \\
\bfseries vhodnimi in \\
\bfseries izhodnimi motoričnimi \\
\bfseries nevroni} \\ \hline
% ------- STDP parameters (delayed_synapse) -------
tip & Tip sinapse & \makecell[l]{Zakasnjena dopaminsko \\ modulirana STDP sinapsa} \\ \hline
\(\tau_{c}\) & Odtekanje \textit{eligibility} sledi & 5 ms \\ \hline
\(\tau_{c\text{, delay}}\) & Zakasnitev sledi $c$ & 200 ms \\ \hline
\(\tau_{n}\) & Odtekanje dopaminske sledi & 10 ms \\ \hline
\(\tau_{+}\) & Pozitivna STDP konstanta & 20 ms \\ \hline
\(b\) & Bazalna dopaminska koncentracija & 0.1  \\ \hline
\(A_{+}\) & Pozitivni STDP multiplikator & 1.5 \\ \hline
\(A_{-}\) & Negativni STDP multiplikator & 1.0 \\ \hline
\(W_{\min,a}\) & Minimalna utež & 500 \\ \hline
\(W_{\max,a}\) & Maksimalna utež & 4000 \\ \hline
\(w_{\text{in, motor}\to a}\) & \makecell[l]{Začetne uteži sinaps med \\ vhodnimi in izhodnimi \\ motoričnimi nevroni} & \(\mathcal{N}(1300, 1)\) \\ \hline
\end{tabular}
\caption{Parametri sinaps med vhodnimi in motoričnimi nevroni}
\end{table}
\\
\begin{table}[H]
\begin{tabular}{lll}
\textbf{Simbol} & \textbf{Pomen} & \textbf{Vrednost} \\ \hline
\thead[l]{\bfseries Parametri sinaps med \\
\bfseries vhodnimi nevroni \\
\bfseries in striatumom} \\ \hline
% ------- STDP parameters (delayed_synapse) -------
tip & Tip sinapse & \makecell[l]{Zakasnjena dopaminsko \\ modulirana STDP sinapsa} \\ \hline
\(\tau_{c}\) & Odtekanje \textit{eligibility} sledi & 5 ms \\ \hline
\(\tau_{c\text{, delay}}\) & Zakasnitev sledi $c$ & 200 ms \\ \hline
\(\tau_{n}\) & Odtekanje dopaminske sledi & 10 ms \\ \hline
\(\tau_{+}\) & Pozitivna STDP konstanta & 20 ms \\ \hline
\(b\) & Bazalna dopaminska koncentracija & 0.1  \\ \hline
\(A_{+}\) & Pozitivni STDP multiplikator & 1.5 \\ \hline
\(A_{-}\) & Negativni STDP multiplikator & 1.0 \\ \hline
\(W_{\min,str}\) & Minimalna utež & 150 \\ \hline
\(W_{\max,str}\) & Maksimalna utež & 1000 \\ \hline
\(w_{\text{in}\to \text{str}}\) & \makecell[l]{Začetne uteži sinaps med \\ vhodnimi in striatum nevroni} & \(\mathcal{N}(150, 8)\) \\ \hline

% ------- Synaptic weights (key model pathways) -------
\end{tabular}
\caption{Parametri sinaps med vhodom in striatumom}
\end{table}
\begin{table}[H]
\begin{tabular}{lll}
\textbf{Simbol} & \textbf{Pomen} & \textbf{Vrednost} \\ \hline
tip & Tip sinapse & \makecell[l]{Privzeta konstantna \\ NEST sinapsa} \\ \hline
\(w_{\text{str}\to\text{vp}}\) & \makecell[l]{Uteži sinps med striatumom in \\ ventral pallidumom} & -50 \\ \hline
\(w_{\text{str}\to\text{dopa}}\) & \makecell[l]{Uteži sinps med striatumom in \\ dopaminergičnimi nevroni} & -55 \\ \hline
\(w_{\text{vp}\to\text{dopa}}\) & \makecell[l]{Uteži sinps med \\ ventral pallidumom in \\ dopaminergičnimi nevroni} & -65 \\ \hline
\(d_{\text{dir}}\) & \makecell[l]{Zakasnitev sinaps \\ direktne povezave} & 200 ms \\ \hline
\end{tabular}
\caption{Parametri sinaps kritika}
\end{table}
\\
\begin{table}[H]
\begin{tabular}{lll}
\textbf{Simbol} & \textbf{Pomen} & \textbf{Vrednost} \\ \hline
% ------- External noise and background -------
\(\lambda_{\text{vp}}\) & \makecell[l]{Povprečna hitrost šumnih impulzov nevronov ventral palliduma} & 5200 \\ \hline
\(\lambda_{\text{dopa}}\) & \makecell[l]{Povprečna hitrost šumnih impulzov v dopaminergičnih nevronov} & 4000 \\ \hline
\(\lambda_{\text{in, motor}}\) & \makecell[l]{Povprečna hitrost šumnih impulzov \\ vhodnih motoričnih nevronov} & $100$ Hz \\ \hline
\(\lambda_{\text{out, motor}}\) & \makecell[l]{Povprečna hitrost šumnih impulzov \\ izhodnih motoričnih nevronov} & $100$ Hz \\ \hline
\end{tabular}
\caption{Parametri generatorjev šuma}
\end{table}
\\
\subsection{Učenje}
\begin{figure}[H]
\begin{center}
\includegraphics[width=1.0\textwidth]{actorcritic/F2 - StateTransitionTD_annotated}
\end{center}
\caption{Prikaz obnašanja sistema ob prehodu iz stanja 0 v nagrajeno stanje 5 in nazaj v stanje 0. Pričakovana nagrada in tako tudi vrednost stanja 0 se ob prehodu v stanje 5 zviša preko povezav do striatuma. Ob prehodu iz nagrajenega stanja (ki pa samega sebe še ne ocenjuje z visoko vrednostjo) nazaj v stanje 0 preidemo iz stanja z osnovnimi utežmi v stanje 0 z okrepljenimi utežmi do striatuma, torej prehod v stanje z višjo vrednostjo. Posledica tega je, napram osnovni frekvenci dopaminergičnih nevronov, povišana dopaminergična aktivnost, ki povzroči aktivnosti sorazmerno povišanje uteži sinaps stanja 5 do striatuma. Ob prehodu iz stanja 0 v stanje 0 se vrnemo k osnovni dopaminergični frekvenci.}
\label{pic8}
\end{figure}
\colorbox{Apricot}{%
  \parbox{0.9\linewidth}{%
    \textbf{
      Potrebna podrobnejša razlaga...
    }%
  }%
}
\begin{figure}[H]
\begin{center}
\includegraphics[width=1.0\textwidth]{actorcritic/F3 - Learning}
\end{center}
\caption{Obnašanje sistema tekom učenja na 3x3 mreži. Polja so oštevilčena od leve proti desni od zgoraj navzdol. Cilj se nahaja na polju 8. Povezave vhoda do striatuma stanj 5 in 7 so pričakovano najvišje, sledi pa jim 4, ki neposredno vodi v 5 in 7}
\\
\colorbox{Apricot}{%
  \parbox{0.9\linewidth}{%
    \textbf{
      Iz zgornje kolekcije grafov izberi izseke, ki predstavljajo ključne situacije med učenjem opisane mehanizme ocenjevanja nagrade in učenja.
    }%
  }%
}

\label{pic8}
\end{figure}
\newpage
\subsection{Rezultati}
Naučeno politiko bomo prikazali podobno kot v poglavju \textbf{R-STDP učenje}, %TODO: link
vendar bomo samozavest izbire akcije v določenem stanju prikazali skupaj z povprečno utežjo povezav med vhodnimi nevroni pripadajočega stanja in striatumom.
\begin{figure}[H]
\begin{center}
\includegraphics[width=0.6\textwidth]{actorcritic/best}
\end{center}
\caption{Rezultat učenja modela na 4x4 mreži tekom 3000 iteracij po 200 ms.}
\label{pic8}
\end{figure}
\\
\colorbox{Apricot}{%
  \parbox{0.9\linewidth}{%
    \textbf{
        Dodaj skalo in razloži preslikavo povprečne uteži v barve polj.
    }%
  }%
}
\\
%TODO: add actual image
\begin{figure}[H]
\begin{center}
\includegraphics[width=1.0\textwidth]{actorcritic/progress}
\end{center}
\caption{Povprečna utež preko sinaps med vsemi vhodnimi nevroni in striatumom tekom 1500 iteracij po 200 ms.}
\label{pic8}
\end{figure}

\subsubsection{Interpretacija rezultatov}
Sistem se uspešno uči politike prehodov iz poljubnega stanja do oddaljene nagrade v kolikor ni nagrada preveč oddaljena. Polja 0 in 4 kažeta v napačno smer, vendar vidimo, da je tudi stanje ocenjeno z nizko vrednostjo. Daljše učenje pri trenutni konfiguraciji ne pripelje do boljših rezultatov. \\
\\
\colorbox{Apricot}{%
  \parbox{0.9\linewidth}{%
    \textbf{
      Potrebna nadaljna analiza. Glavna omejitev učenja je kosntantna rast sinaps tekom učenja.
      Sinapse v trenutnem modelu skozi čas same po sebi odtekajo v povprečju počasneje kot rastejo.
      Tako je nastavljeno, saj se pri redkih nagradah in predvsem v zgodnjih fazah učenja razlike v sinapsah zaradi nagrade bolje ohranijo.
    }%
  }%
}
%TODO: Rešitev je ovrednotena tudi po metrikah podobnih tem uporabljenim v diplomski nalogi Svete A \cite{vozicekSPalico}.

\chapter{Implementacija in uporabljena orodja}
\label{methodology_and_tools}
Rešitve so implementirane v jeziku Pythonu, kjer za simulacijo uporabljamo simulator \href{https://www.nest-simulator.org/}{NEST}, ki ima zaledje implementirano v C++. Za simulator, ki ga uporabljamo preko Pythonovega vmesnika je v sklopu tega diplomskega dela implementiran tudi modul, ki je prav tako implementiran v C++. V sklopu te naloge uporaba impulznih nevronskih mrež zunaj simuliranega okolja, na trdo-ožičenih nevronskih čipih ali na robotih ni pokrito, zato posebna oprema za ta namen ni bila uporabljena. Sistemi, razviti v diplomski nalogi so poleg medsebojne primerjave ovrednoteni tudi z drugimi trenutno obstoječimi implementacijami spodbujevanega učenja na impulznih nevronskih mrežah. 
\\
\\
\\
\colorbox{Apricot}{%
  \parbox{0.9\linewidth}{%
    \textbf{ 
        Napiši več o pisanju modula za NEST simulator, s katerim smo v nadaljevanju implementirali zakasnjeno RSTDP sinapso.
    }%
  }%
}
\\
\\
\colorbox{Apricot}{%
  \parbox{0.9\linewidth}{%
    \textbf{
        Napiši par stavkov o komunikaciji z zaledjem NEST, ki nam je omogočala spremljanje internih parametrov sinaps.
    }%
  }%
}
\chapter{Diskusija in zaključek}
\colorbox{Apricot}{%
  \parbox{0.9\linewidth}{%
    \textbf{
        To-Do...
    }%
  }%
}
%\cleardoublepage
%\addcontentsline{toc}{chapter}{Literatura}

%\printbibliography[heading=bibintoc,type=article,title={Članki v revijah}]
%https://www.overleaf.com/project/609ce2055f917cb2f776732e
%\printbibliography[heading=bibintoc,type=inproceedings,title={Članki v zbornikih}]
%\printbibliography[heading=bibintoc,type=incollection,title={Poglavja v knjigah}]
\printbibliography[heading=bibintoc,title={Viri}]


\end{document}
